{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from PIL import Image\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from matplotlib import gridspec\n",
    "from scipy import stats\n",
    "\n",
    "# Set plot style and size\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color Clustering Analysis\n",
    "# 1. Load and explore the data\n",
    "def load_data(file_path='downscaled_thumbnails.csv'):\n",
    "    \"\"\"Load the color profile data\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "df = load_data()\n",
    "\n",
    "# # Display the first few rows\n",
    "# print(\"\\nFirst 5 rows:\")\n",
    "# display(df.head())\n",
    "\n",
    "# # Basic statistics\n",
    "# print(\"\\nBasic statistics:\")\n",
    "# display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Visualize the distribution of colors across all images\n",
    "def plot_color_distribution(df):\n",
    "    \"\"\"Plot the average distribution of colors across all images\"\"\"\n",
    "    # Drop the 'Name' column for calculations\n",
    "    colors_only = df.drop('Name', axis=1)\n",
    "    \n",
    "    # Calculate the mean percentage for each color\n",
    "    color_means = colors_only.mean().sort_values(ascending=False)\n",
    "    \n",
    "    # Create a bar plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(color_means.index, color_means.values)\n",
    "    \n",
    "    # Color each bar with its corresponding color\n",
    "    for i, bar in enumerate(bars):\n",
    "        color_name = bar.get_x()\n",
    "        if color_name in ['Yellow', 'Orange', 'Red', 'Violet', 'Blue', 'Green', 'Brown', 'Black', 'White']:\n",
    "            bar.set_color(color_name.lower())\n",
    "        else:\n",
    "            bar.set_color('gray')\n",
    "    \n",
    "    plt.title('Average Color Distribution Across All Images')\n",
    "    plt.ylabel('Percentage (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_color_distribution(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prepare data for clustering\n",
    "def prepare_data_for_clustering(df):\n",
    "    \"\"\"Prepare the data for clustering by separating features and scaling\"\"\"\n",
    "    # Extract features (color percentages) and image names\n",
    "    X = df.drop('Name', axis=1).values\n",
    "    image_names = df['Name'].values\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return X_scaled, image_names, scaler\n",
    "\n",
    "X_scaled, image_names, scaler = prepare_data_for_clustering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Find optimal number of clusters using silhouette score\n",
    "def find_optimal_clusters(X, max_k=10):\n",
    "    \"\"\"Determine the optimal number of clusters using silhouette score\"\"\"\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    for k in range(2, max_k + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(X)\n",
    "        score = silhouette_score(X, kmeans.labels_)\n",
    "        silhouette_scores.append(score)\n",
    "        print(f\"Silhouette score for k={k}: {score}\")\n",
    "    \n",
    "    # Plot silhouette scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(2, max_k + 1), silhouette_scores, 'bo-')\n",
    "    plt.title('Silhouette Score Method')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Return the optimal k (adding 2 because we start at k=2)\n",
    "    return silhouette_scores.index(max(silhouette_scores)) + 2\n",
    "\n",
    "# Find optimal number of clusters\n",
    "optimal_k = find_optimal_clusters(X_scaled)\n",
    "print(f\"Optimal number of clusters: {optimal_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Perform clustering with optimal k\n",
    "def perform_clustering(X, k):\n",
    "    \"\"\"Perform KMeans clustering\"\"\"\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    return kmeans, labels\n",
    "\n",
    "kmeans, labels = perform_clustering(X_scaled, optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters_pca_with_centroids(X, labels, image_names):\n",
    "    \"\"\"Visualize clusters in 2D using PCA with a side-by-side plot showing centroids\"\"\"\n",
    "    # Apply PCA to reduce to 2 dimensions for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    \n",
    "    # Create DataFrame for easier plotting\n",
    "    pca_df = pd.DataFrame({'PCA1': X_pca[:, 0], 'PCA2': X_pca[:, 1], \n",
    "                          'Cluster': labels, 'Image': image_names})\n",
    "    \n",
    "    # Calculate cluster centroids in original space\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    centroids_orig = np.zeros((n_clusters, X.shape[1]))\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        centroids_orig[i] = np.mean(X[labels == i], axis=0)\n",
    "    \n",
    "    # Project centroids onto PCA space\n",
    "    centroids_pca = pca.transform(centroids_orig)\n",
    "    \n",
    "    # Create a figure with two subplots side by side\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    # Left plot: All data points\n",
    "    sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=pca_df, palette='viridis', s=80, ax=ax1)\n",
    "    ax1.set_title('All Data Points in PCA Space')\n",
    "    ax1.legend(title='Cluster')\n",
    "    \n",
    "    # Right plot: Centroids only\n",
    "    # First plot all points with reduced opacity for context\n",
    "    sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=pca_df, palette='viridis', \n",
    "                   s=30, alpha=0.2, legend=False, ax=ax2)\n",
    "    \n",
    "    # Then plot centroids as larger points with labels\n",
    "    for i in range(n_clusters):\n",
    "        ax2.scatter(centroids_pca[i, 0], centroids_pca[i, 1], s=200, c=f'C{i}', \n",
    "                   marker='*', edgecolors='black', linewidth=1.5, label=f'Centroid {i}')\n",
    "        ax2.annotate(f'Cluster {i}', (centroids_pca[i, 0], centroids_pca[i, 1]),\n",
    "                   xytext=(10, 5), textcoords='offset points', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    ax2.set_title('Cluster Centroids in PCA Space')\n",
    "    ax2.legend(title='Centroids', loc='upper right')\n",
    "    \n",
    "    # Add information about variance explained\n",
    "    explained_var = pca.explained_variance_ratio_\n",
    "    fig.suptitle(f'Cluster Visualization (PCA1: {explained_var[0]:.1%} variance, PCA2: {explained_var[1]:.1%} variance)',\n",
    "                fontsize=16)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return pca, X_pca, centroids_pca\n",
    "\n",
    "# Call the updated function\n",
    "pca, X_pca, centroids_pca = visualize_clusters_pca_with_centroids(X_scaled, labels, image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Analyze cluster characteristics\n",
    "def analyze_clusters(df, labels, k):\n",
    "    \"\"\"Analyze the characteristics of each cluster\"\"\"\n",
    "    # Add cluster labels to the original DataFrame\n",
    "    df_clustered = df.copy()\n",
    "    df_clustered['Cluster'] = labels\n",
    "    \n",
    "    # Calculate mean color percentages for each cluster\n",
    "    numeric_cols = df_clustered.select_dtypes(include=['number']).columns\n",
    "    numeric_cols = [col for col in numeric_cols if col != 'Cluster']\n",
    "    cluster_means = df_clustered.groupby('Cluster')[numeric_cols].mean()\n",
    "    \n",
    "    # Arrange plots in a grid instead of vertical stack for better visibility\n",
    "    cols = 2  # Number of columns in the grid\n",
    "    rows = math.ceil(k / cols)  # Calculate required rows\n",
    "    \n",
    "    # Create larger figure to accommodate the grid\n",
    "    plt.figure(figsize=(20, 5 * rows))\n",
    "    \n",
    "    for i in range(k):\n",
    "        # Create subplot in grid layout\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        \n",
    "        cluster_profile = cluster_means.iloc[i]\n",
    "        \n",
    "        # Set bar width explicitly for better visibility\n",
    "        width = 0.7\n",
    "        bar_positions = np.arange(len(cluster_profile.index))\n",
    "        bars = plt.bar(bar_positions, cluster_profile.values, width=width)\n",
    "        \n",
    "        # Color each bar appropriately\n",
    "        for bar, color_name in zip(bars, cluster_profile.index):\n",
    "            if color_name.lower() in ['yellow', 'orange', 'red', 'violet', 'blue', 'green', 'brown', 'black', 'white']:\n",
    "                bar.set_color(color_name.lower())\n",
    "            else:\n",
    "                bar.set_color('gray')\n",
    "        \n",
    "        # Add value labels on top of each bar for clarity\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            if height > 3:  # Only label bars with significant values\n",
    "                plt.text(\n",
    "                    bar.get_x() + bar.get_width()/2.,\n",
    "                    height + 0.5,\n",
    "                    f'{height:.1f}%',\n",
    "                    ha='center', \n",
    "                    va='bottom', \n",
    "                    rotation=0,\n",
    "                    fontsize=9\n",
    "                )\n",
    "                \n",
    "        plt.title(f'Cluster {i} (n={sum(labels == i)})', fontsize=14)\n",
    "        plt.ylim(0, max(cluster_means.values.max() * 1.15, 10))  # Expand y-axis a bit more for labels\n",
    "        plt.xticks(bar_positions, cluster_profile.index, rotation=45)\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    plt.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    return df_clustered, cluster_means\n",
    "\n",
    "df_clustered, cluster_means = analyze_clusters(df, labels, optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cluster_examples(df_clustered, image_dir=\"../thumbnails\", num_examples=10):\n",
    "    \"\"\"\n",
    "    Display example images from each cluster with max 5 images per row (without color bars)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_clustered : pandas DataFrame\n",
    "        DataFrame containing image data with Cluster column\n",
    "    image_dir : str\n",
    "        Directory path where the images are stored\n",
    "    num_examples : int\n",
    "        Number of example images to show per cluster\n",
    "    \"\"\"\n",
    "    for cluster_id in sorted(df_clustered['Cluster'].unique()):\n",
    "        cluster_samples = df_clustered[df_clustered['Cluster'] == cluster_id]\n",
    "        samples = cluster_samples.sample(min(num_examples, len(cluster_samples)))\n",
    "        \n",
    "        print(f\"Cluster {cluster_id} examples (showing {len(samples)} out of {len(cluster_samples)}):\")\n",
    "        \n",
    "        # Limit to 5 images per row\n",
    "        images_per_row = 5\n",
    "        n_samples = len(samples)\n",
    "        n_rows = math.ceil(n_samples / images_per_row)\n",
    "        \n",
    "        # Create figure with only image rows (no color bars)\n",
    "        fig, axs = plt.subplots(n_rows, images_per_row, \n",
    "                               figsize=(15, 3.5 * n_rows))\n",
    "        fig.suptitle(f'Cluster {cluster_id} (Contains {len(cluster_samples)} images)', fontsize=16)\n",
    "        \n",
    "        # Handle single row case\n",
    "        if n_rows == 1:\n",
    "            axs = np.array([axs])\n",
    "        \n",
    "        # Process each sample\n",
    "        for i, (_, row) in enumerate(samples.iterrows()):\n",
    "            # Calculate position in the grid (no multiplier needed since no color bars)\n",
    "            row_idx = i // images_per_row\n",
    "            col_idx = i % images_per_row\n",
    "            \n",
    "            # Get the correct axes object\n",
    "            img_ax = axs[row_idx, col_idx]\n",
    "            \n",
    "            image_path = os.path.join(image_dir, row['Name'])\n",
    "            \n",
    "            # Try to load and display image\n",
    "            try:\n",
    "                img = Image.open(image_path)\n",
    "                img_ax.imshow(img)\n",
    "                img_ax.set_title(row['Name'], fontsize=10)\n",
    "                img_ax.axis('off')\n",
    "                \n",
    "                # Extract color data for console output only\n",
    "                color_data = {col: row[col] for col in row.index \n",
    "                             if col not in ['Name', 'Cluster']}\n",
    "                \n",
    "                # Sort colors by percentage\n",
    "                sorted_colors = sorted(color_data.items(), key=lambda x: x[1], reverse=True)\n",
    "                \n",
    "                # Print detailed information\n",
    "                print(f\"  - {row['Name']}: \", end=\"\")\n",
    "                significant_colors = {k: f\"{v:.1f}%\" for k, v in sorted_colors if v > 5.0}\n",
    "                print(significant_colors)\n",
    "                \n",
    "            except Exception as e:\n",
    "                img_ax.text(0.5, 0.5, f\"Image not found\\n{row['Name']}\", \n",
    "                          horizontalalignment='center', verticalalignment='center')\n",
    "                img_ax.axis('off')\n",
    "                print(f\"  - Error loading {row['Name']}: {e}\")\n",
    "        \n",
    "        # Hide any unused subplots\n",
    "        for i in range(n_samples, n_rows * images_per_row):\n",
    "            row_idx = i // images_per_row\n",
    "            col_idx = i % images_per_row\n",
    "            axs[row_idx, col_idx].axis('off')\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.9, hspace=0.2)\n",
    "        plt.show()\n",
    "        print()\n",
    "\n",
    "# To use this function, just specify your image directory:\n",
    "display_cluster_examples(df_clustered, image_dir=\"../thumbnails\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster sizes and distribution\n",
    "cluster_counts = df_clustered['Cluster'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(cluster_counts.index, cluster_counts.values)\n",
    "\n",
    "# Color each bar according to dominant color in that cluster\n",
    "for i, bar in enumerate(bars):\n",
    "    dominant_color = cluster_means.iloc[i].idxmax()\n",
    "    if dominant_color.lower() in ['yellow', 'orange', 'red', 'violet', 'blue', 'green', 'brown', 'black', 'white']:\n",
    "        bar.set_color(dominant_color.lower())\n",
    "    else:\n",
    "        bar.set_color('gray')\n",
    "\n",
    "plt.title('Number of Images per Cluster')\n",
    "plt.xlabel('Cluster ID')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(cluster_counts.index)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add count labels above bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'{height}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most distinctive colors for each cluster\n",
    "# Define numeric_cols (color columns) by selecting numeric columns excluding 'Cluster'\n",
    "numeric_cols = df_clustered.select_dtypes(include=['number']).columns\n",
    "numeric_cols = [col for col in numeric_cols if col != 'Cluster']\n",
    "\n",
    "all_means = df_clustered[numeric_cols].mean()\n",
    "distinctiveness = pd.DataFrame(index=cluster_means.index, columns=cluster_means.columns)\n",
    "\n",
    "for cluster in cluster_means.index:\n",
    "    for color in cluster_means.columns:\n",
    "        # How much higher/lower is this color's percentage in this cluster vs. overall?\n",
    "        distinctiveness.loc[cluster, color] = cluster_means.loc[cluster, color] / all_means[color]\n",
    "\n",
    "# Display most distinctive colors (those with highest ratio compared to overall average)\n",
    "for cluster in distinctiveness.index:\n",
    "    distinct_colors = distinctiveness.loc[cluster].sort_values(ascending=False)\n",
    "    print(f\"\\nCluster {cluster} distinctive colors:\")\n",
    "    for color, ratio in distinct_colors.items():\n",
    "        if ratio > 1.2:  # Only show colors that appear at least 20% more than average\n",
    "            print(f\"  - {color}: {ratio:.2f}x the average ({cluster_means.loc[cluster, color]:.1f}% vs overall {all_means[color]:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze variation within clusters\n",
    "# Calculate standard deviation of each color within each cluster\n",
    "cluster_stds = df_clustered.groupby('Cluster')[numeric_cols].std()\n",
    "\n",
    "# Plot the standard deviations as a heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(cluster_stds, annot=True, fmt='.1f', cmap='viridis')\n",
    "plt.title('Color Variation Within Each Cluster (Standard Deviation)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find the most homogeneous and heterogeneous clusters\n",
    "mean_stds = cluster_stds.mean(axis=1).sort_values()\n",
    "print(\"\\nClusters from most homogeneous to most heterogeneous:\")\n",
    "for cluster, std in mean_stds.items():\n",
    "    print(f\"Cluster {cluster}: Average std dev = {std:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_representative_images(df_clustered, X_scaled, kmeans, n=10, images_per_row=5):\n",
    "    \"\"\"Find and display the most representative images in each cluster (closest to centroid)\"\"\"\n",
    "    representatives = {}\n",
    "    \n",
    "    # Determine number of clusters and calculate cluster sizes\n",
    "    n_clusters = len(kmeans.cluster_centers_)\n",
    "    cluster_sizes = df_clustered['Cluster'].value_counts().sort_index()\n",
    "    \n",
    "    # Generate a distinct color for each cluster\n",
    "    cluster_colors = plt.cm.tab10(np.linspace(0, 1, n_clusters))\n",
    "    \n",
    "    # Process each cluster separately\n",
    "    for cluster_id in range(n_clusters):\n",
    "        # Get indices of images in this cluster\n",
    "        in_cluster = df_clustered['Cluster'] == cluster_id\n",
    "        cluster_size = sum(in_cluster)\n",
    "        \n",
    "        if cluster_size == 0:\n",
    "            continue\n",
    "            \n",
    "        # Calculate distances to centroid\n",
    "        cluster_points = X_scaled[in_cluster]\n",
    "        centroid = kmeans.cluster_centers_[cluster_id].reshape(1, -1)\n",
    "        distances = euclidean_distances(cluster_points, centroid)\n",
    "        \n",
    "        # Get indices of points closest to centroid\n",
    "        closest_indices = np.argsort(distances.flatten())[:n]\n",
    "        \n",
    "        # Translate to original DataFrame indices\n",
    "        original_indices = np.where(in_cluster)[0][closest_indices]\n",
    "        representative_images = df_clustered.iloc[original_indices]\n",
    "        \n",
    "        representatives[cluster_id] = representative_images\n",
    "        \n",
    "        # Create a new figure for this cluster\n",
    "        rows = int(np.ceil(min(n, cluster_size) / images_per_row))\n",
    "        plt.figure(figsize=(images_per_row * 3, rows * 3 + 1))\n",
    "        \n",
    "        # Add cluster title with statistics\n",
    "        plt.suptitle(f\"Cluster {cluster_id}: {cluster_size} images\", \n",
    "                    fontsize=16, y=0.98)\n",
    "        \n",
    "        # Display representative images\n",
    "        for i, (idx, img) in enumerate(representative_images.iterrows()):\n",
    "            if i >= n:\n",
    "                break\n",
    "                \n",
    "            ax = plt.subplot(rows, images_per_row, i + 1)\n",
    "            \n",
    "            # Add colored border based on cluster\n",
    "            ax.spines['bottom'].set_color(cluster_colors[cluster_id])\n",
    "            ax.spines['top'].set_color(cluster_colors[cluster_id]) \n",
    "            ax.spines['right'].set_color(cluster_colors[cluster_id])\n",
    "            ax.spines['left'].set_color(cluster_colors[cluster_id])\n",
    "            ax.spines['bottom'].set_linewidth(5)\n",
    "            ax.spines['top'].set_linewidth(5) \n",
    "            ax.spines['right'].set_linewidth(5)\n",
    "            ax.spines['left'].set_linewidth(5)\n",
    "            \n",
    "            # Clean up filename for display\n",
    "            filename = img['Name']\n",
    "            short_name = filename[:15] + '...' if len(filename) > 15 else filename\n",
    "            \n",
    "            # Load and display the image\n",
    "            image_path = f\"../thumbnails/{filename}\"\n",
    "            try:\n",
    "                image = plt.imread(image_path)\n",
    "                plt.imshow(image)\n",
    "                plt.title(short_name, fontsize=10)\n",
    "                plt.axis('off')\n",
    "            except Exception as e:\n",
    "                plt.text(0.5, 0.5, f\"Missing image\", ha='center', va='center')\n",
    "                plt.gca().set_facecolor('#f0f0f0')  # Light gray background for missing images\n",
    "                \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust for suptitle\n",
    "        plt.show()\n",
    "    \n",
    "    return representatives\n",
    "\n",
    "# Call with the new parameter for controlling images per row\n",
    "representative_images = find_representative_images(df_clustered, X_scaled, kmeans, n=10, images_per_row=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cluster comparison plot (radar chart)\n",
    "def plot_cluster_comparison(cluster_means):\n",
    "    \"\"\"Create radar charts to compare clusters\"\"\"\n",
    "    # Normalize the data for radar chart\n",
    "    normalized_means = cluster_means.div(cluster_means.max(axis=1), axis=0)\n",
    "    \n",
    "    # Set up the figure\n",
    "    fig = plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Plot 4 clusters per row\n",
    "    clusters_per_row = 4\n",
    "    rows = math.ceil(len(cluster_means) / clusters_per_row)\n",
    "    \n",
    "    # Categories for the radar chart\n",
    "    categories = cluster_means.columns\n",
    "    N = len(categories)\n",
    "    \n",
    "    # Create angle for each category\n",
    "    angles = np.linspace(0, 2*np.pi, N, endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Close the loop\n",
    "    \n",
    "    for i, cluster in enumerate(normalized_means.index):\n",
    "        ax = fig.add_subplot(rows, clusters_per_row, i+1, polar=True)\n",
    "        \n",
    "        # Values for this cluster, add first value at end to close the loop\n",
    "        values = normalized_means.loc[cluster].values.flatten().tolist()\n",
    "        values += values[:1]\n",
    "        \n",
    "        # Plot and fill\n",
    "        ax.plot(angles, values, linewidth=2, label=f\"Cluster {cluster}\")\n",
    "        ax.fill(angles, values, alpha=0.25)\n",
    "        \n",
    "        # Set category labels\n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels(categories, size=8)\n",
    "        \n",
    "        # Set title\n",
    "        ax.set_title(f\"Cluster {cluster}\", size=11)\n",
    "        \n",
    "        # Remove radial labels\n",
    "        ax.set_yticklabels([])\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_cluster_comparison(cluster_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which colors contribute most to principal components\n",
    "def analyze_pca_components(X_scaled, feature_names, pca):\n",
    "    \"\"\"Analyze which features (colors) contribute most to each principal component\"\"\"\n",
    "    # Get loadings (feature contributions to components)\n",
    "    loadings = pca.components_\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i, component in enumerate(loadings[:2]):  # Analyze two components\n",
    "        plt.subplot(3, 1, i+1)\n",
    "        \n",
    "        # Sort contributions by absolute value\n",
    "        sorted_idx = np.argsort(np.abs(component))[::-1]\n",
    "        sorted_features = [feature_names[j] for j in sorted_idx]\n",
    "        sorted_loadings = component[sorted_idx]\n",
    "        \n",
    "        # Create horizontal bar chart\n",
    "        bars = plt.barh(np.arange(len(sorted_features)), sorted_loadings)\n",
    "        \n",
    "        # Color bars by feature name\n",
    "        for j, (bar, feature) in enumerate(zip(bars, sorted_features)):\n",
    "            if feature.lower() in ['yellow', 'orange', 'red', 'violet', 'blue', 'green', 'brown', 'black', 'white']:\n",
    "                bar.set_color(feature.lower())\n",
    "            else:\n",
    "                bar.set_color('gray')\n",
    "        \n",
    "        plt.axvline(x=0, color='gray', linestyle='--')\n",
    "        plt.yticks(np.arange(len(sorted_features)), sorted_features)\n",
    "        plt.title(f'Feature Contributions to PC{i+1} (Explains {pca.explained_variance_ratio_[i]:.1%} of variance)')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Run the analysis (assuming you have X_scaled, feature_names, and pca from previous analysis)\n",
    "feature_names = numeric_cols  # Your color column names\n",
    "analyze_pca_components(X_scaled, feature_names, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! EXPERIMENTAL CODE (NOT SURE IF THIS MAKES SENSE)\n",
    "\n",
    "def calculate_color_metrics(df):\n",
    "    \"\"\"Calculate contrast and saturation metrics for each image based on color distribution\"\"\"\n",
    "    # Drop the 'Name' column for calculations\n",
    "    colors_only = df.drop('Name', axis=1)\n",
    "    \n",
    "    # Define color properties (approximate values)\n",
    "    color_properties = {\n",
    "        'Yellow': {'luminance': 0.8, 'saturation': 0.8},\n",
    "        'Orange': {'luminance': 0.6, 'saturation': 0.9},\n",
    "        'Red': {'luminance': 0.5, 'saturation': 1.0},\n",
    "        'Violet': {'luminance': 0.4, 'saturation': 0.7},\n",
    "        'Blue': {'luminance': 0.3, 'saturation': 0.8},\n",
    "        'Green': {'luminance': 0.5, 'saturation': 0.7},\n",
    "        'Brown': {'luminance': 0.3, 'saturation': 0.4},\n",
    "        'Black': {'luminance': 0.0, 'saturation': 0.0},\n",
    "        'White': {'luminance': 1.0, 'saturation': 0.0}\n",
    "    }\n",
    "    \n",
    "    # Initialize result dataframe\n",
    "    result = pd.DataFrame(index=df.index)\n",
    "    result['Name'] = df['Name']\n",
    "    \n",
    "    # Calculate metrics for each image\n",
    "    for idx, row in colors_only.iterrows():\n",
    "        # Contrast: standard deviation of color percentages\n",
    "        result.at[idx, 'color_variance'] = row.std()\n",
    "        \n",
    "        # Weighted luminance contrast\n",
    "        luminance_values = [color_properties[color]['luminance'] * row[color]/100 \n",
    "                           for color in color_properties.keys() if color in row.index]\n",
    "        if luminance_values:\n",
    "            result.at[idx, 'luminance_contrast'] = max(luminance_values) - min(luminance_values)\n",
    "        else:\n",
    "            result.at[idx, 'luminance_contrast'] = 0\n",
    "            \n",
    "        # Weighted average saturation\n",
    "        weighted_saturation = sum(color_properties[color]['saturation'] * row[color]/100 \n",
    "                                 for color in color_properties.keys() if color in row.index)\n",
    "        result.at[idx, 'avg_saturation'] = weighted_saturation\n",
    "        \n",
    "    return result\n",
    "\n",
    "def visualize_color_metrics(df, metrics_df):\n",
    "    \"\"\"Visualize relationships between color distributions and calculated metrics\"\"\"\n",
    "    # Create a new figure\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 1. Dominant color vs metrics\n",
    "    plt.subplot(2, 2, 1)\n",
    "    colors_only = df.drop('Name', axis=1)\n",
    "    dominant_colors = colors_only.idxmax(axis=1)\n",
    "    \n",
    "    sns.boxplot(x=dominant_colors, y=metrics_df['avg_saturation'])\n",
    "    plt.title('Saturation by Dominant Color')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 2. Contrast vs Saturation scatter plot\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.scatterplot(x='avg_saturation', y='luminance_contrast', data=metrics_df)\n",
    "    plt.title('Contrast vs Saturation')\n",
    "    \n",
    "    # 3. Distribution of metrics\n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.histplot(metrics_df['avg_saturation'], kde=True)\n",
    "    plt.title('Distribution of Saturation Values')\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    sns.histplot(metrics_df['luminance_contrast'], kde=True)\n",
    "    plt.title('Distribution of Contrast Values')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate correlations between color percentages and metrics\n",
    "    print(\"Correlations between color percentages and metrics:\")\n",
    "    corr_data = pd.concat([colors_only, metrics_df[['avg_saturation', 'luminance_contrast', 'color_variance']]], axis=1)\n",
    "    correlation_matrix = corr_data.corr()\n",
    "    \n",
    "    # Show correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    plt.title('Correlation between Colors and Metrics')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Calculate metrics and visualize\n",
    "metrics_df = calculate_color_metrics(df)\n",
    "visualize_color_metrics(df, metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Save the results (optional)\n",
    "# df_clustered.to_csv('clustered_thumbnails.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
